{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬農糧署的資料再把結果轉成csv檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爬農糧署全球資訊網囉\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import requests\n",
    "import pyquery\n",
    "import pandas as pd\n",
    "###新建工作簿，写入内容，关闭工作簿\n",
    "from openpyxl import Workbook\n",
    "#from openpyxl.compat import range\n",
    "from openpyxl.utils import get_column_letter\n",
    "print(\"爬農糧署全球資訊網囉\")\n",
    "\n",
    "afa_url = 'https://www.afa.gov.tw/cht/index.php?'\n",
    "\n",
    "req = requests.get(afa_url)\n",
    "page = req.text\n",
    "pq = pyquery.PyQuery(page)\n",
    "more_data = pq('.text-right').find('a')\n",
    "now_url = \"https://www.afa.gov.tw/cht/\"+more_data.attr('href')\n",
    "# 按下更多 進入農業新聞https://www.afa.gov.tw/cht/index.php?code=list&ids=307\n",
    "number = input(\"要爬幾頁呢 :  \")\n",
    "news_list =[]\n",
    "article_date = []\n",
    "article_source= [] \n",
    "article_content= []\n",
    "for j in range(int(number)):\n",
    "    req2 = requests.get(now_url)\n",
    "    page2 = req2.text\n",
    "    pq2 = pyquery.PyQuery(page2)\n",
    "    #找到9篇\n",
    "    article_data = pq2('.agricultural-news-content').find('a')\n",
    "    # article_data_url= article_data.attr('href')\n",
    "    for data in article_data: \n",
    "        #取到9個url\n",
    "        article_data_url= pq(data).attr('href')\n",
    "        #進入到單一文章\n",
    "        req3 = requests.get(article_data_url)\n",
    "        page3 = req3.text\n",
    "        pq3 = pyquery.PyQuery(page3)\n",
    "        article_date = pq3('.agricultural-news-content-title .col-md-12').text()\n",
    "        article_date = article_date[5:]\n",
    "        article_content = pq3('.shared-content-text').text()\n",
    "        article_content = article_content.split(\"\\n\")\n",
    "        article_content = ''.join(article_content) \n",
    "#         .split(\"\\n\")\n",
    "#         .replace(\" \", \"\")\n",
    "#         .split(\"\\n\")\n",
    "        article_source_and_update_date =pq3('.pt-md').text()\n",
    "        article_source, update_date = article_source_and_update_date.split(\"更新日期：\")\n",
    "        article_source = article_source[5:]\n",
    "        article_source = article_source.strip('\\n')\n",
    "        print(article_date)\n",
    "        print(article_content)\n",
    "        print(\"---------\")\n",
    "        print(article_source)\n",
    "        print(\"-----------------------------------------------------\")\n",
    "        news_dict = {'日期' : article_date, '來源' : article_source, '新聞' : article_content}\n",
    "        news_list.append(news_dict)\n",
    "    next_page_url = pq2('.page').find('a')\n",
    "    now_url = (pq(next_page_url[11]).attr('href'))\n",
    "    print(now_url)\n",
    "    \n",
    "#轉成dataframe \n",
    "df = pd.DataFrame(news_list, columns=['日期', '來源', '新聞'])\n",
    "#儲存成csv檔\n",
    "df.to_csv('result1.csv')\n",
    "print(\"爬完囉\")\n",
    "\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
